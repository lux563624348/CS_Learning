{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_file(file_path, num_rows):\n",
    "    ## num_rows has to be a 2 elements list\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        row_range=range(num_rows[0],num_rows[1]+1)\n",
    "        i=0\n",
    "        for line in file:\n",
    "            if (i in row_range):               \n",
    "                   print (line)\n",
    "            i+=1\n",
    "    return None\n",
    "\n",
    "def return_letter_list(start_letter, end_letter):\n",
    "    alpha=start_letter\n",
    "    letter_list=list()\n",
    "    for i in range(0,26):\n",
    "        letter_list.append(alpha)\n",
    "        if (alpha==end_letter):\n",
    "            break\n",
    "        alpha= chr(ord(alpha)+1)\n",
    "    return letter_list\n",
    "\n",
    "def filter_alphanumeric(word):\n",
    "#\\w matches any alphanumeric character\n",
    "    if (word!=''):\n",
    "        all_match = re.findall('\\w+', word)\n",
    "        all_match = list(filter(None, all_match))\n",
    "        merge_words=''\n",
    "        for item in all_match:\n",
    "            merge_words+=item\n",
    "        ## Find All unicode, then all non digits\n",
    "        merge_words=re.findall('[^(\\_|\\d)]', merge_words)\n",
    "        merge_words_no_digit=''\n",
    "        for item in merge_words:\n",
    "            merge_words_no_digit+=item        \n",
    "    else:\n",
    "        print (\"Error!\")\n",
    "    return merge_words_no_digit.lower()\n",
    "\n",
    "\n",
    "def return_word_list_from_file(Path_File):\n",
    "    list_words=list()\n",
    "    with open(Path_File,  mode='r', newline='') as file:\n",
    "        for line in file:\n",
    "            for word in (re.split(\"\\s+\", line.rstrip('\\n'))):\n",
    "                if (word !=''):\n",
    "                    list_words.append(filter_alphanumeric(word))\n",
    "## if different languague, above line has to be changed\n",
    "    list_words = list(filter(None, list_words))\n",
    "    list_words = given_word_marker(list_words)\n",
    "    return list_words\n",
    "\n",
    "def given_word_marker(word_list):\n",
    "    marked_word_list=list()\n",
    "    for word in word_list:\n",
    "        marked_word_list.append('^'+word+'$')\n",
    "    return marked_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renturn Statistic Training Calculation\n",
    "def return_alphabet_from_words_list(list_word):\n",
    "    total_alphabet=set()\n",
    "    for word in list_word:\n",
    "        for letter in set(word):\n",
    "            total_alphabet.add(letter)\n",
    "    return sorted(list(total_alphabet))\n",
    "\n",
    "def return_bigram_counts(word_list, alphabet):\n",
    "    count_matrix=np.zeros((len(alphabet),len(alphabet)))\n",
    "    #count_matrix+=1\n",
    "    alpha_a_digit=ord('a')\n",
    "    num_word=0\n",
    "    for tem_word in word_list:\n",
    "        num_word+=1\n",
    "        for i in range(len(tem_word)-1):\n",
    "            tem_bigram_count_pairs = tem_word[i:i+2]\n",
    "            first_letter=tem_bigram_count_pairs[0]\n",
    "            second_letter=tem_bigram_count_pairs[1]\n",
    "            ## Because marker ^ and $ take two space      \n",
    "            ## convert to numberic value\n",
    "            first_digit=alphabet.index(first_letter)\n",
    "            second_digit=alphabet.index(second_letter)\n",
    "            count_matrix[first_digit,second_digit]+=1\n",
    "    print (\"Number of Words: \"+ str(num_word))\n",
    "    return count_matrix\n",
    "\n",
    "def return_unigram_counts(word_list, alphabet):\n",
    "    count_matrix=np.zeros((len(alphabet)))\n",
    "    alpha_a_digit=ord('a')\n",
    "    for tem_word in word_list:\n",
    "        for i in range(len(tem_word)):\n",
    "            letter_value=alphabet.index(tem_word[i])\n",
    "            ## Because marker ^ and $ take two space\n",
    "            count_matrix[letter_value]+=1\n",
    "    return count_matrix\n",
    "\n",
    "def Norm_Bigram(unigram_counts, bigram_counts, alphabet):\n",
    "    alpha_a_digit=ord('a')\n",
    "    norm_bigram=np.zeros((len(alphabet),len(alphabet)))\n",
    "    for i in range(len(alphabet)):\n",
    "        norm_bigram[i,:]=bigram_counts[i,:]/unigram_counts[i]\n",
    "    return norm_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Probability Session for Model\n",
    "## MLE Log Likelyhood\n",
    "def return_Probability_of_word(input_word, norm_bigram_model, alphabet):\n",
    "    Log_P_word=0\n",
    "    filtered_input_word = filter_alphanumeric(input_word)\n",
    "    if(filtered_input_word==''):\n",
    "        Log_P_word+=0\n",
    "    else:\n",
    "        tem_word='^'+filtered_input_word+'$'\n",
    "        for i in range(len(tem_word)-1):\n",
    "            tem_bigram_count_pairs = tem_word[i:i+2]\n",
    "            if((tem_bigram_count_pairs[0] in alphabet) & (tem_bigram_count_pairs[1] in alphabet)):\n",
    "                first_digit=alphabet.index(tem_bigram_count_pairs[0])\n",
    "                second_digit=alphabet.index(tem_bigram_count_pairs[1])\n",
    "                if(norm_bigram_model[first_digit][second_digit]!=0):\n",
    "                    Log_P_word += np.log(norm_bigram_model[first_digit][second_digit])\n",
    "                else:\n",
    "                    Log_P_word +=0\n",
    "            else:\n",
    "                Log_P_word+=0\n",
    "    return np.e**(Log_P_word)\n",
    "\n",
    "def return_Probability_of_Sentence(sentence, norm_bigram_counts, alphabet):\n",
    "    sentence = re.split(\"\\s+\", sentence.rstrip('\\n'))\n",
    "    Log_Probability_sentence = 0\n",
    "    ## Filter Null Element\n",
    "    sentence = list(filter(None, sentence))\n",
    "    for word in sentence[1:]:\n",
    "        p_word=return_Probability_of_word(word, norm_bigram_counts,alphabet)\n",
    "        if (p_word!=0):\n",
    "            Log_Probability_sentence += np.log(p_word)\n",
    "        else:\n",
    "            Log_Probability_sentence += 0\n",
    "    return np.e**Log_Probability_sentence\n",
    "\n",
    "def return_probability(Path_Test_Data, Norm_Bigram_counts, Alphabet):\n",
    "    count_matrix=list()\n",
    "    with open(Path_Test_Data,  mode='r', newline='') as file:\n",
    "        i=0\n",
    "        for line in file:\n",
    "            results= return_Probability_of_Sentence(line, Norm_Bigram_counts, Alphabet)\n",
    "            count_matrix.append(results)\n",
    "            i+=1\n",
    "    return count_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main\n",
    "def test_with_model(path_train_data, path_test_data):\n",
    "    ## first generate words list\n",
    "    test_word = return_word_list_from_file(path_train_data)\n",
    "    ## build up alphabet with ^ and $\n",
    "    alphabet = return_alphabet_from_words_list(test_word)\n",
    "\n",
    "    raw_unigram_counts =return_unigram_counts(test_word,alphabet)\n",
    "    raw_bigram_counts  =return_bigram_counts(test_word,alphabet)    \n",
    "    norm_bigram_counts =Norm_Bigram(raw_unigram_counts, raw_bigram_counts, alphabet)\n",
    "\n",
    "    # test data output\n",
    "    prob = return_probability(path_test_data, norm_bigram_counts, alphabet)\n",
    "    return prob\n",
    "\n",
    "def Save_Results(En_prob,FR_prob,GR_prob, NAME):\n",
    "    data_prob_output = np.transpose([En_prob,FR_prob,GR_prob])\n",
    "    index_LANG=['EN','FR','GR']\n",
    "    out_index=list()\n",
    "    i=1\n",
    "    for prob_row in data_prob_output[:]:\n",
    "        index_l = list(prob_row).index(max(prob_row))\n",
    "        out_index.append([i,index_LANG[index_l]])\n",
    "        i+=1\n",
    "    pd.DataFrame(out_index,columns=['ID','LANG']).set_index('ID').to_csv('Results_'+ NAME + '_Model.txt', sep=\"\\t\")\n",
    "    print(\"Output Results can be found at the current directory!\")\n",
    "    print(\"Output Name is: \"+ 'Results_'+ NAME + '_Model.txt')\n",
    "    return data_prob_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Words: 30612\n",
      "Number of Words: 33634\n",
      "Number of Words: 27399\n",
      "Output Results can be found at the current directory!\n",
      "Output Name is: Results_Letter_Bigram_Model.txt\n"
     ]
    }
   ],
   "source": [
    "Path_Data='Data/'\n",
    "Train_Data_Set=['EN.txt', 'FR.txt', 'GR.txt']\n",
    "Path_test_data = Path_Data+'LangID.test.txt'\n",
    "All_prob=list()\n",
    "for name_train in Train_Data_Set:\n",
    "    Path_train_data = Path_Data+name_train\n",
    "    All_prob.append(test_with_model(Path_train_data, Path_test_data))\n",
    "\n",
    "\n",
    "NAME='Letter_Bigram'\n",
    "output = Save_Results(All_prob[0],All_prob[1],All_prob[2], NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Word Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
